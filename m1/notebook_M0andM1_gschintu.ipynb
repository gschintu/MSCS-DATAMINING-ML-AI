{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894a55a6",
   "metadata": {
    "id": "el9sjRdm9gjv"
   },
   "source": [
    "# **`Giuseppe Schintu - M.0 and M.1 Tasks & Answers`**\n",
    "\n",
    "# **`M.1.Introduction to data mining`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X-de8q4f_q13",
   "metadata": {
    "id": "X-de8q4f_q13"
   },
   "source": [
    "## **`exercise.M.1`** - Python Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cW6PQ4KAFhfd",
   "metadata": {
    "id": "cW6PQ4KAFhfd"
   },
   "source": [
    "### **`Overview and Directions`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZR2SKZ0V4l36",
   "metadata": {
    "id": "ZR2SKZ0V4l36"
   },
   "source": [
    "### **`Task.1`**  - comma-separated values (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c910b9",
   "metadata": {
    "id": "cs55wtGeEV7u"
   },
   "source": [
    "Reading and parsing [delimiter-separated values](https://en.wikipedia.org/wiki/Delimiter-separated_values) files like [comma-separated](https://en.wikipedia.org/wiki/Comma-separated_values) and [tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values) is a regular data science preprocessing activity. It is typically acceptable to request either file format for analysis activities.    \n",
    "- *.csv* files store tabular data like numbers and text in a plain text format. \n",
    "- Plain text may include text, white spaces, carriage returns, transliterals, and other artifacts.    \n",
    "- Each row, or data record, contains a value or nothing. A comma separates each.    \n",
    "\n",
    "**`Tasks`**  \n",
    "0. Read in the Nobel prize winners name and age data: [data.M.1.exercise.csv](https://github.com/cosc-526/home.page/blob/main/data.M.1.exercise.csv)  \n",
    "=> data is in class github. Read however you like!  \n",
    "1. Generate a single value for the total number of rows of data.\n",
    "2. Generate a single value for the total number of columns of data.  \n",
    "3. Calculate the laureates average age as a datatype float.  \n",
    "4. Solution structured as a user defined function (def) but doing so not required.   \n",
    "5. hint  \n",
    ".> use library `import requests` to read numerics from a url  \n",
    "=> mydata = requests.get(file_url)  \n",
    "==> if mydata.status_code == 200:  #200 = code for a successful request  \n",
    "====> do something with lines\n",
    "\n",
    "**`Useful links`**  \n",
    "- [Ch.16, Importing Data, Python.Crash.Course, Matthes](https://github.com/cosc-526/cosc.526.home.page/blob/main/textbook.Python.crash.course.matthes.pdf)  \n",
    "[open](https://docs.python.org/3.6/library/functions.html#open), \n",
    "[readlines](https://docs.python.org/3.6/library/codecs.html#codecs.StreamReader.readlines), [rstrip](https://docs.python.org/3.6/library/stdtypes.html#str.rstrip), [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions), [split](https://docs.python.org/3.6/library/stdtypes.html#str.split), [splice](https://docs.python.org/3.6/glossary.html#term-slice), [\"list.love\"](https://docs.python.org/3.6/tutorial/datastructures.html#more-on-lists), [len](https://docs.python.org/3.6/library/functions.html#len), [int](https://docs.python.org/3.6/library/functions.html#int), [format](https://docs.python.org/3.6/library/stdtypes.html#str.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Azp65ID2UV9X",
   "metadata": {
    "id": "Azp65ID2UV9X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "def process_nobel_data():\n",
    "    # Fetch the CSV file from the GitHub link\n",
    "    file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.exercise.csv\"\n",
    "    response = requests.get(file_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Read the CSV data and calculate required values\n",
    "        data = response.text.splitlines()\n",
    "        csv_reader = csv.reader(data)\n",
    "        header = next(csv_reader)  # Skip the header row\n",
    "        \n",
    "        # Task 1: Generate a single value for the total number of rows of data\n",
    "        total_rows = sum(1 for _ in csv_reader)\n",
    "        \n",
    "        # Reset the reader back to the start\n",
    "        csv_reader = csv.reader(data)\n",
    "        next(csv_reader)  # Skip the header row again\n",
    "        \n",
    "        # Task 2: Generate a single value for the total number of columns of data\n",
    "        total_columns = len(header)\n",
    "        \n",
    "        # Task 3: Calculate the laureates average age as a datatype float\n",
    "        age_sum = 0\n",
    "        for row in csv_reader:\n",
    "            age = float(row[1])  # age is in the second column (index 1)\n",
    "            age_sum += age\n",
    "        average_age = age_sum / total_rows\n",
    "        \n",
    "        return total_rows, total_columns, average_age\n",
    "    \n",
    "    else:\n",
    "        print(\"Error: Failed to retrieve the CSV file.\")\n",
    "\n",
    "# Call the function and store the results\n",
    "rows, columns, avg_age = process_nobel_data()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of rows of data:\", rows)\n",
    "print(\"Number of cols:\", columns)\n",
    "print(\"Average Age:\", avg_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fFtuKBBh4l4C",
   "metadata": {
    "id": "fFtuKBBh4l4C"
   },
   "source": [
    "**Task.1 Expected ouput**\n",
    "```\n",
    "Number of rows of data: 8\n",
    "Number of cols: 3\n",
    "Average Age: 70.875\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LSr6LhyN4l4E",
   "metadata": {
    "id": "LSr6LhyN4l4E"
   },
   "source": [
    "### **`Task.3`** - Convert diacritics (ä, ö) to ASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CdUDaILLI7Ro",
   "metadata": {
    "id": "CdUDaILLI7Ro"
   },
   "source": [
    "- Download [data.M.1.exercise.csv](https://github.com/cosc-526/home.page/blob/main/data.M.1.exercise.csv) and right click on the file to view in Notepad.   \n",
    "=> Observe the Unicode non-English letters in laureates' names like the two dots over the letter \"o\" in \"Schrödinger.\"\n",
    "- Learn about [Unicode](https://en.wikipedia.org/wiki/Unicode) character standards for representing different types and forms of text.  \n",
    "- Grok that Python 3 [natively supports](https://docs.python.org/3/howto/unicode.html) Unicode, but many tools don't.\n",
    "- Conversion of Unicode to [ASCII](https://en.wikipedia.org/wiki/ASCII) formatting is often necessary in data preprocessing.  \n",
    "\n",
    "**Tasks**\n",
    "0. Read this article on diacritics conversion (e.g., \"ü\" → \"ue\"); [transliteration](https://german.stackexchange.com/questions/4992/conversion-table-for-diacritics-e-g-%C3%BC-%E2%86%92-ue).  \n",
    "1. data = [data.M.1.exercise.csv](https://github.com/cosc-526/home.page/blob/main/data.M.1.exercise.csv)  \n",
    "=> provided example reads directly from github\n",
    "2. Analyze and run code block with a dictionary matching Unicode character \"keys\" to their ASCII transliteration \"value.\"\n",
    "=> as a refresher, a dictionary is defined as mydict = { key:value }\n",
    "3. For labeled code sections #3.1 to 3.9, explain succinctly what the code is accomplishing and whether you are or are not familiar with it.  \n",
    "4. Create your inventory mechanism to store this, and more, code blocks.  \n",
    "\n",
    "***More useful links***\n",
    "- [1: replace](https://docs.python.org/3.6/library/stdtypes.html#str.replace), [2: file object methods](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects),  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "XnJm4ImJDSgW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnJm4ImJDSgW",
    "outputId": "0e497da6-c3ee-44fc-98db-f4c5056a3ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Phillips Feynman\n",
      "Shin'ichiro Tomonaga\n",
      "Julian Schwinger\n",
      "Rudolf Ludwig Moessbauer\n",
      "Erwin Schroedinger\n",
      "Paul Dirac\n",
      "Maria Sklodowska-Curie\n",
      "Pierre Curie\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "translit_dict = {\n",
    "    \"ä\" : \"ae\",\n",
    "    \"ö\" : \"oe\",\n",
    "    \"ü\" : \"ue\",\n",
    "    \"Ä\" : \"Ae\",\n",
    "    \"Ö\" : \"Oe\",\n",
    "    \"Ü\" : \"Ue\", \n",
    "    \"ł\" : \"l\",\n",
    "    \"ō\" : \"o\",\n",
    "}\n",
    "#3.0\n",
    "#read data from a URL\n",
    "def parse_delimited_file(file_url, delimiter):\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        lines = response.text.split('\\n')\n",
    "    else:\n",
    "        print('Failed to fetch the file from GitHub.')\n",
    "        return\n",
    "    lines = [line.rstrip('\\n') for line in lines if line.strip()]  # Skip empty lines\n",
    "    return lines\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.exercise.csv\"\n",
    "lines = parse_delimited_file(file_url, delimiter=\",\")\n",
    "\n",
    "#3.1\n",
    "#with open(\"data.exercise.M.1.csv\", 'r', encoding='utf8') as csvfile:\n",
    "#    lines = csvfile.readlines()\n",
    "#3.2\n",
    "# Strip off the newline from the end of each line\n",
    "lines = [line.rstrip() for line in lines]\n",
    "\n",
    "#3.3   \n",
    "# Split each line based on the delimiter (which, in this case, is the comma)\n",
    "split_lines = [line.split(\",\") for line in lines]\n",
    "\n",
    "#3.4\n",
    "# Separate the header from the data\n",
    "header = split_lines[0]\n",
    "data_lines = split_lines[1:]\n",
    "    \n",
    "#3.5    \n",
    "# Find \"name\" within the header\n",
    "name_index = header.index(\"name\")\n",
    "\n",
    "#3.6\n",
    "# Extract the names from the rows\n",
    "unicode_names = [line[name_index] for line in data_lines]\n",
    "\n",
    "#3.7\n",
    "# Iterate over the names\n",
    "translit_names = []\n",
    "for unicode_name in unicode_names:\n",
    "    # Perform the replacements in the translit_dict\n",
    "    # HINT: ref [1]\n",
    "    translit_name = unicode_name\n",
    "    for key, value in translit_dict.items():\n",
    "        translit_name = translit_name.replace(key, value)\n",
    "    translit_names.append(translit_name)\n",
    "\n",
    "#3.8\n",
    "# Write out the names to a file named \"data-ascii.txt\"\n",
    "# HINT: ref [2]\n",
    "with open(\"data.exercise.M.1.ascii.txt\", 'w') as outfile:\n",
    "    for name in translit_names:\n",
    "        outfile.write(name + \"\\n\")\n",
    "#3.9\n",
    "# Verify that the names were converted and written out correctly\n",
    "with open(\"data.exercise.M.1.ascii.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        print(line.rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X6tBzbFR2f_v",
   "metadata": {
    "id": "X6tBzbFR2f_v"
   },
   "outputs": [],
   "source": [
    "#=>Enter answer/reflection   \n",
    "#3.1\n",
    "#3.2 populate lines object while stripping off the newline from the end of each line\n",
    "#3.3 Split each line based on the delimiter (which, in this case, is the comma)\n",
    "#3.4 Separate the header from the data\n",
    "#3.5 Find \"name\" within the header\n",
    "#3.6 Extract the names from the rows\n",
    "#3.7 Iterate over the names and replace character matches with translit_dict key/value.\n",
    "#3.8 Write out the names to a file named \"data-ascii.txt\"\n",
    "#3.9 Verify that the names were converted and written out correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zmOzzRTl4l4P",
   "metadata": {
    "id": "zmOzzRTl4l4P"
   },
   "source": [
    "**`Expected output`**\n",
    "```\n",
    "Richard Phillips Feynman\n",
    "Shin'ichiro Tomonaga\n",
    "Julian Schwinger\n",
    "Rudolf Ludwig Moessbauer\n",
    "Erwin Schroedinger\n",
    "Paul Dirac\n",
    "Maria Sklodowska-Curie\n",
    "Pierre Curie\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09fcd7",
   "metadata": {
    "id": "5f09fcd7"
   },
   "source": [
    "## **`assign.M.1.assignment.1`** - Data Mining with Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ujMShg_DwKdx",
   "metadata": {
    "id": "ujMShg_DwKdx"
   },
   "source": [
    "### **`Overview and Directions`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orcAiqUZAQ6Y",
   "metadata": {
    "id": "orcAiqUZAQ6Y"
   },
   "source": [
    "1. Import and manipulate a .csv file  \n",
    "2. Assess your Python Programming Skills  \n",
    "3. Other assignments are more challenging; use this to assess your skills.\n",
    "4. Prepare questions for a class discussion to help source additional tools. \n",
    "5. Perform tasks without assistance from clever sources.    \n",
    "\n",
    "#### **`Desired outcomes`**  \n",
    "- Experience Pandas dataframes to group, aggregate, find, sort, and calculate.  \n",
    "- Perform calculations to find best country, rank, and total items processed. \n",
    "- Note: Pandas is reviewed in Module 2 and quality resources provided below.  \n",
    "\n",
    "#### **`Additional resources`**  \n",
    "- [Daniel Chen](https://github.com/chendaniely/) is a **generous** Pandas master.  \n",
    "=> Purchase of his books is recommended; not a solicitation!    \n",
    "- [Chen,D.,(2022). Pandas for everyone, 2nd.Ed.](https://www.amazon.com/Pandas-Everyone-Analysis-Addison-Wesley-Analytics/dp/0137891156/ref=sr_1_1?crid=T9BF3HU24YFL&keywords=pandas+for+everyone&qid=1685205022&sprefix=pandas+for+everyone%2Caps%2C203&sr=8-1)  \n",
    "=> [groupby](https://github.com/chendaniely/2017-10-26-python_crash_course/blob/gh-pages/notebooks/07-groupby.ipynb) => [missing values](https://github.com/chendaniely/2017-10-26-python_crash_course/blob/gh-pages/notebooks/03-missing.ipynb) => [many more!](https://github.com/chendaniely/2017-10-26-python_crash_course/tree/gh-pages/notebooks)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNiLo5Rm9SM2",
   "metadata": {
    "id": "RNiLo5Rm9SM2"
   },
   "source": [
    "### **`Task.0`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wcrKuRsWXUW1",
   "metadata": {
    "id": "wcrKuRsWXUW1"
   },
   "source": [
    "#### **`Dataset`**\n",
    "- source information => COVID-19 variant [sequencing](https://www.cdc.gov/coronavirus/2019-ncov/variants/genomic-surveillance.html#:~:text=Scientists%20use%20a%20process%20called%20genomic%20sequencing%20to%20identify%20SARS,test%20positive%20for%20COVID%2D19) by countries.   \n",
    "Data fields    \n",
    "1. `location`: the country providing information.    \n",
    "2. `date`: data entry date.  \n",
    "3. `variant`: the COVID-19 variant for the entered record.  \n",
    "4. `num_sequences`: the number of sequences **processed** by country, variant, and date.   \n",
    "5. `num_sequences_total`: the number of sequences **available** by country, variant, and date.  \n",
    "6. `perc_sequences`: the percentage of the available sequences processed (*out of 100*)  \n",
    "`note:` each dataset row represents *one* variant by *one* country on *one* day.  \n",
    "\n",
    "**`Tasks`**  \n",
    "1. Locate and read dataset into a pandas.DataFrame called 'df' via  \n",
    "a. A Kaggle API; use existing or acquire; [Kaggle.covid.dataset](https://www.kaggle.com/yamqwe/omicron-covid19-variant-daily-cases?select=covid-variants.csv)  \n",
    "or  \n",
    "b. Class github URL or another .csv method like [Matthes, Ch.16](https://github.com/cosc-526/cosc.526.home.page/blob/main/textbook.Python.crash.course.matthes.pdf)    \n",
    "=> filename: [data.M.1.assignment.covid.data.csv](https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv)    \n",
    "=>**consider** reading a Github data URL requires a path to **raw data**    \n",
    "2. Display the DataFrame's first 5 rows.  \n",
    "3. Display descriptive stats confirming: 100,416 data records.  \n",
    "4. Round DataFrame to 1 decimal place!   \n",
    "\n",
    "**`Useful links`**  \n",
    "[Built-in Functions](https://docs.python.org/3/library/functions.html#built-in-functions)  \n",
    "[pandas.DataFrame documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "J6JeWBO2Cw78",
   "metadata": {
    "id": "J6JeWBO2Cw78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame header\n",
      "   location        date    variant  num_sequences  perc_sequences  \\\n",
      "0   Angola  2020-07-06      Alpha              0             0.0   \n",
      "1   Angola  2020-07-06  B.1.1.277              0             0.0   \n",
      "2   Angola  2020-07-06  B.1.1.302              0             0.0   \n",
      "3   Angola  2020-07-06  B.1.1.519              0             0.0   \n",
      "4   Angola  2020-07-06    B.1.160              0             0.0   \n",
      "\n",
      "   num_sequences_total  \n",
      "0                    3  \n",
      "1                    3  \n",
      "2                    3  \n",
      "3                    3  \n",
      "4                    3  \n",
      "\n",
      "\n",
      "Dataframe descriptive statistics, rounded to tenths\n",
      "        num_sequences  perc_sequences  num_sequences_total\n",
      "count       100416.0        100416.0             100416.0\n",
      "mean            72.2             6.2               1509.6\n",
      "std           1669.3            21.9               8445.3\n",
      "min              0.0            -0.0                  1.0\n",
      "25%              0.0             0.0                 12.0\n",
      "50%              0.0             0.0                 59.0\n",
      "75%              0.0             0.0                394.0\n",
      "max         142280.0           100.0             146170.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "\n",
    "#use head() to display first 5 rows\n",
    "print(\"DataFrame header\\n\",df.head())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# use describe() to print descriptive stats\n",
    "print(\"Dataframe descriptive statistics, rounded to tenths\\n\",df.describe())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4z6COkzkC2KU",
   "metadata": {
    "id": "4z6COkzkC2KU"
   },
   "source": [
    "#### **`Task.0 - Expected Outcome`**  \n",
    "```\n",
    "DataFrame header\n",
    "  location  date        variant  num_sequences  perc_sequences  num_sequences_total\n",
    "0   Angola  2020-07-06      Alpha              0             0.0   3\n",
    "1   Angola  2020-07-06  B.1.1.277              0             0.0   3\n",
    "2   Angola  2020-07-06  B.1.1.302              0             0.0   3\n",
    "3   Angola  2020-07-06  B.1.1.519              0             0.0   3\n",
    "4   Angola  2020-07-06    B.1.160              0             0.0   3\n",
    "\n",
    "Dataframe descriptive statistics, rounded to tenths\n",
    "       num_sequences  perc_sequences  num_sequences_total\n",
    "count       100416.0        100416.0             100416.0\n",
    "mean            72.0             6.0               1510.0\n",
    "std           1669.0            22.0               8445.0\n",
    "min              0.0            -0.0                  1.0\n",
    "25%              0.0             0.0                 12.0\n",
    "50%              0.0             0.0                 59.0\n",
    "75%              0.0             0.0                394.0\n",
    "max         142280.0           100.0             146170.0 \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c5a8f",
   "metadata": {
    "id": "760c5a8f"
   },
   "source": [
    "### **`Task.1`** - Find uncommon variants  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZGy_VBO4DDyd",
   "metadata": {
    "id": "ZGy_VBO4DDyd"
   },
   "source": [
    "The U.S. experienced the COVID-19 `Alpha`, `Delta`, `Omicron`  \n",
    "\n",
    "**`Tasks`**  \n",
    "0. In whatever object you like, e.g. list, dataframe, etc  \n",
    "1. Get unique variant items for category: **`US_and_other`**  \n",
    "=> where variants == [US, `non_who`, `others`]  \n",
    "2. Get unique variant items for category: **`nonUS_and_other`**  \n",
    "=> where variants != [US, `non_who`, `others`]  \n",
    "3. Print your chosen objects to display unique variant categories.  \n",
    "4. Show a total unique count for each, and total for dataset,\n",
    "\n",
    "**`Useful links`**   \n",
    "- [len()](https://docs.python.org/3/library/functions.html#len)\n",
    "- [list comprehension w Bro Code](https://www.youtube.com/watch?v=fcLDzKH_5XM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "vxMduRg5Cj5u",
   "metadata": {
    "id": "vxMduRg5Cj5u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alpha' 'Delta' 'Omicron' 'others' 'non_who']\n",
      "\n",
      "\n",
      "total US + other =  5\n",
      "\n",
      "\n",
      "['B.1.1.277' 'B.1.1.302' 'B.1.1.519' 'B.1.160' 'B.1.177' 'B.1.221'\n",
      " 'B.1.258' 'B.1.367' 'B.1.620' 'Beta' 'Epsilon' 'Eta' 'Gamma' 'Iota'\n",
      " 'Kappa' 'Lambda' 'Mu' 'S:677H.Robin1' 'S:677P.Pelican']\n",
      "\n",
      "\n",
      "total nonUS+other =  19\n",
      "\n",
      "\n",
      "total unique variants =  24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "#Instructions and Expected Outcome don't match, so fix query to match expected outcome\n",
    "#where variants == [US, non_who, others]\n",
    "df1 = df.query(\"((variant in ('Alpha', 'Delta', 'Omicron', 'non_who', 'others' ) and num_sequences_total > 0) and (location in ('United States')))\")\n",
    "print(df1[\"variant\"].unique())\n",
    "print(\"\\n\")\n",
    "print(\"total US + other = \", len(df1[\"variant\"].unique()))\n",
    "\n",
    "#Instructions and Expected Outcome don't match, so fix query to match expected outcome\n",
    "#where variants != [US, non_who, others]\n",
    "df2 = df.query(\"((variant not in ('Alpha', 'Delta', 'Omicron', 'non_who', 'others' ) and num_sequences_total > 0) and (location not in ('United States')))\")\n",
    "print(\"\\n\")\n",
    "print(df2[\"variant\"].unique())\n",
    "print(\"\\n\")\n",
    "print(\"total nonUS+other = \", len(df2[\"variant\"].unique()))\n",
    "print(\"\\n\")\n",
    "print(\"total unique variants = \", len(df[\"variant\"].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jBOVMJ0zck9a",
   "metadata": {
    "id": "jBOVMJ0zck9a"
   },
   "source": [
    "#### **`Task.1 - Expected Outcome`**  \n",
    "```\n",
    "note: organization of output can vary widely!  \n",
    "\n",
    "['Alpha', 'Delta', 'Omicron', 'others', 'non_who']  \n",
    "\n",
    "total US + other =  5\n",
    "\n",
    "['B.1.1.277', 'B.1.1.302', 'B.1.1.519', 'B.1.160', 'B.1.177', 'B.1.221',  \n",
    " 'B.1.258', 'B.1.367', 'B.1.620', 'Beta', 'Epsilon', 'Eta', 'Gamma', 'Iota',  \n",
    "  'Kappa', 'Lambda', 'Mu', 'S:677H.Robin1', 'S:677P.Pelican']   \n",
    "  \n",
    "total nonUS+other =  19   \n",
    "\n",
    "total unique variants =  24 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aB6-dtiH5OSq",
   "metadata": {
    "id": "aB6-dtiH5OSq"
   },
   "source": [
    "### **`Task.2`** - Find the most processed variant  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bRbxoQb9rbN9",
   "metadata": {
    "id": "bRbxoQb9rbN9"
   },
   "source": [
    "**Tasks**  \n",
    "1. Which variant of COVID-19 has the most sequences processed?  \n",
    "2. Store and print the result in a string called **`variant_most_proc`**  \n",
    "\n",
    "**Useful links**  \n",
    "[pd.DataFrame.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas-dataframe-groupby), [pd.DataFrame.aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas-dataframe-aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "JoFZ2N-WFDH1",
   "metadata": {
    "id": "JoFZ2N-WFDH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant of COVID-19 with most sequences processed =  Delta\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "#group by variant, get max value from column 'num_sequences' and select it's max index\n",
    "variant_most_proc = df.groupby(['variant'])['num_sequences'].aggregate('max').idxmax()\n",
    "\n",
    "print(\"variant of COVID-19 with most sequences processed = \", variant_most_proc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5uAWiinsdBi2",
   "metadata": {
    "id": "5uAWiinsdBi2"
   },
   "source": [
    "#### **`Task.2 - Expected Outcome`**  \n",
    "```\n",
    "Delta  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663db8ac",
   "metadata": {
    "id": "663db8ac"
   },
   "source": [
    "### **`Task.3`** - Find the best country at processing ALL variant sequences  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ny95wr5_sQhK",
   "metadata": {
    "id": "ny95wr5_sQhK"
   },
   "source": [
    "**`Tasks`**  \n",
    "1. Which country did the best processing **all** categories.    \n",
    "2. Store the result in a string called **`best_proc_country`**  \n",
    "3. The outcome is a single country.  \n",
    "4. **consider** df.groupby(\"location\").aggregate({\"num_sequences\": \"sum\", \"num_sequences_total\": \"sum\"})\n",
    "\n",
    "**`Useful links`**  \n",
    "[youtube: aggregate with groupby and .agg or .aggregate](https://www.youtube.com/watch?v=PNzlx3CjqAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "75c31b41",
   "metadata": {
    "id": "75c31b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percent performed by country\n",
      "                      num_sequences  num_sequences_total  percent\n",
      "location                                                         \n",
      "Cyprus                         1160                14160     8.19\n",
      "Hungary                         623                 7824     7.96\n",
      "Egypt                          2489                32040     7.77\n",
      "United Arab Emirates           4530                59760     7.58\n",
      "Uruguay                        1189                16368     7.26\n",
      "...                             ...                  ...      ...\n",
      "Seychelles                      554                13032     4.25\n",
      "Slovakia                      17932               423552     4.23\n",
      "Fiji                            533                12600     4.23\n",
      "Brunei                          335                 7944     4.22\n",
      "Vietnam                        1811                43320     4.18\n",
      "\n",
      "[121 rows x 3 columns]\n",
      "the best country is => Cyprus\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "#group by location, and add two new columns to new df2 so we can run easier calculation of percentage\n",
    "df2 = df.groupby(\"location\").aggregate({\"num_sequences\": \"sum\", \"num_sequences_total\": \"sum\"})\n",
    "\n",
    "#add custom formula df2 to calculate percentage with previously added aggregate columns\n",
    "df2[\"percent\"] = (df2[\"num_sequences\"] / df2[\"num_sequences_total\"]) * 100\n",
    "\n",
    "#sort rows by percent before we print out\n",
    "df3 = df2.sort_values(by=[\"percent\"], ascending=False)\n",
    "\n",
    "print(\"Total percent performed by country\")\n",
    "print(df3)\n",
    "\n",
    "#extract percentage by extracting the index with highest percent value \n",
    "best_proc_country = df2['percent'].idxmax()\n",
    "\n",
    "print(\"the best country is =>\", best_proc_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y0bRJhZLdKBu",
   "metadata": {
    "id": "y0bRJhZLdKBu"
   },
   "source": [
    "#### **`Task.3 - Expected Outcome`**\n",
    "```\n",
    "Total percent performed by country \n",
    "\n",
    "location                percent\n",
    "Cyprus                  8.19\n",
    "Hungary                 7.96\n",
    "Egypt                   7.77\n",
    "United Arab Emirates    7.58\n",
    "Uruguay                 7.26\n",
    "                        ... \n",
    "Seychelles              4.25\n",
    "Fiji                    4.23\n",
    "Slovakia                4.23\n",
    "Brunei                  4.22\n",
    "Vietnam                 4.18\n",
    "Name: perc_sequences, Length: 121, dtype: float64 \n",
    "\n",
    "the best country is =>  Cyprus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1d3a0",
   "metadata": {
    "id": "11d1d3a0"
   },
   "source": [
    "### **`Task.4a`** - Find the best country at processing specific variant sequences  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jxd-0IN00go_",
   "metadata": {
    "id": "Jxd-0IN00go_"
   },
   "source": [
    "**`Tasks`**  \n",
    "1. Which country is best at processing sequences for Alpha, Delta, and Omicron variants?    \n",
    "2. Store and print the result in a string called **`best_proc_country_ADO`** \n",
    "3. The final output is a single country.  \n",
    "\n",
    "**`Useful links`** \n",
    "- ibid  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fcafdd2e",
   "metadata": {
    "id": "fcafdd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percent performed by country\n",
      "            num_sequences  num_sequences_total  percent\n",
      "location                                               \n",
      "Vietnam              1799                 5415    33.22\n",
      "Brunei                326                  993    32.83\n",
      "Fiji                  517                 1575    32.83\n",
      "Slovakia            17327                52944    32.73\n",
      "Maldives              845                 2595    32.56\n",
      "...                   ...                  ...      ...\n",
      "Egypt                 181                 4005     4.52\n",
      "Hungary                29                  978     2.97\n",
      "Madagascar             27                 2316     1.17\n",
      "Cyprus                 20                 1770     1.13\n",
      "Uruguay                 0                 2046     0.00\n",
      "\n",
      "[121 rows x 3 columns]\n",
      "best_proc_country_ADO =  Vietnam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "df.query(\"variant in ('Alpha','Delta','Omicron')\", inplace=True)\n",
    "\n",
    "#group by location, and add two new columns to new df2 so we can run easier calculation of percentage\n",
    "df2 = df.groupby(\"location\").aggregate({\"num_sequences\": \"sum\", \"num_sequences_total\": \"sum\"})\n",
    "\n",
    "#add custom formula df2 to calculate percentage with previously added aggregate columns\n",
    "df2[\"percent\"] = (df2[\"num_sequences\"] / df2[\"num_sequences_total\"]) * 100\n",
    "\n",
    "#sort rows by percent before we print out\n",
    "df3 = df2.sort_values(by=[\"percent\"], ascending=False)\n",
    "\n",
    "print(\"Total percent performed by country\")\n",
    "print(df3)\n",
    "\n",
    "#extract percentage by extracting the index with highest percent value \n",
    "best_proc_country_ADO = df2['percent'].idxmax()\n",
    "\n",
    "print(\"best_proc_country_ADO = \", best_proc_country_ADO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fvANdWH2kOqc",
   "metadata": {
    "id": "fvANdWH2kOqc"
   },
   "source": [
    "#### **`Task.4a - Expected Outcome`**  \n",
    "```\n",
    "best_proc_country_ADO = Vietnam  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb8782",
   "metadata": {
    "id": "9ccb8782"
   },
   "source": [
    "### **`Task.4b`** - Find the United States ranking for processing Alpha, Delta, and Omicron  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uS-CWHXDFnlB",
   "metadata": {
    "id": "uS-CWHXDFnlB"
   },
   "source": [
    "**`Tasks`**  \n",
    "Given the outcome in 4a\n",
    "1. Find the positional index value for the US ranking for processing sequences for Alpha, Delta, an Omicron variants.   \n",
    "2. Store and print the ranking as an integer in a **us_ranking** variable.  \n",
    "3. Ensure your ranking scale reflects a scale starting at 1.  \n",
    "4. As a refresher, Python indexing starts at 0.  \n",
    "\n",
    "**`Useful links`** \n",
    "- [enumerate](https://docs.python.org/3/library/functions.html#enumerate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "038e81b5",
   "metadata": {
    "id": "038e81b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States ranking =  [57]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "df.query(\"variant in ('Alpha','Delta','Omicron')\", inplace=True)\n",
    "\n",
    "#group by location, and add three new columns to new df2 so we can run easier calculation of percentage and also access location column\n",
    "df2 = df.groupby(\"location\", group_keys=False).aggregate({\"location\":\"max\",\"num_sequences\": \"sum\", \"num_sequences_total\": \"sum\"})\n",
    "\n",
    "#add custom formula df2 to calculate percentage with previously added aggregate columns\n",
    "df2[\"percent\"] = (df2[\"num_sequences\"] / df2[\"num_sequences_total\"]) * 100\n",
    "\n",
    "#sort rows by percent in descending order (Best to worst in processing variants)\n",
    "df3 = df2.sort_values(by=[\"percent\"], ascending=False)\n",
    "\n",
    "#prepare list comprehension with enumerate over location column until we find 'United States'\n",
    "us_ranking = [i for (i, v) in enumerate(df3[\"location\"], start=1) if v == \"United States\"]\n",
    "\n",
    "print(\"United States ranking = \", us_ranking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G5SUmnTckQBM",
   "metadata": {
    "id": "G5SUmnTckQBM"
   },
   "source": [
    "#### **`Task.4b - Expected Outcome`**  \n",
    "```\n",
    "United States ranking = 57  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e46d3",
   "metadata": {
    "id": "283e46d3"
   },
   "source": [
    "### **`Task.5.<final.task>` - Write instructions for a jr. data scientist assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qhqwnKBcvW7R",
   "metadata": {
    "id": "qhqwnKBcvW7R"
   },
   "source": [
    "**`Task =>`**  \n",
    "- Write clear and precise directions that enable your  new junior  \n",
    "- data analyst, aka \"Jr,\" to modify and fix code that you provide.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913dpFR0Fp1E",
   "metadata": {
    "id": "913dpFR0Fp1E"
   },
   "source": [
    "#### **`Grading requirements=>`**  \n",
    "A clear and precise explanation of specific activities for production code your boss needs but you dont have time to fix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2mN_TFHdT1Vg",
   "metadata": {
    "id": "2mN_TFHdT1Vg"
   },
   "source": [
    "Data science requires clear explanations of tasks, methodology, and effective communication with peers. To help the new junior analyst complete their first assignment, provide a concise and precise description including  \n",
    "\n",
    "1. `Sample Outcome`\n",
    "Deliver a comprehensive report summarizing findings and insights from data analysis. Include, as needed, desired outcome format, data objects, and visualizations.  \n",
    "\n",
    "2. `Python Code Explanation`\n",
    "Use plain language to describe specific Python code to achieve the desired outcome. Refer to pandas, Python, and other library documentation to incorporate particular language.  \n",
    "\n",
    "3. `Consider Deprecated Functions`\n",
    "The provided code is outdated and broken. Encourage problem-solving skills and leverage previous experience with similar tasks. Provide relevant links for reverse engineering.  \n",
    "\n",
    "**`Additional personnel considerations`**\n",
    "4. `Plain Language Explanation`\n",
    "Consider the junior analyst's background in C and provide clear and unambiguous instructions.  \n",
    "\n",
    "5. `Documentation Reference`\n",
    "Emphasize where to consult pandas, Python, and other library documentation to discern code mechanics and clarify concepts.  \n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b6a379",
   "metadata": {
    "id": "TOdZMTe-Rcl_"
   },
   "source": [
    "`Your manager's original request => [memo substrate]` \n",
    "\n",
    "`\"hey! i need by lunch` the processed sequences per country on any date`  \n",
    "because as CFO wants to crunch numbers this afternoon - thx Lambda\"\n",
    "\n",
    "1. Determine the percentage of processed sequences for the Alpha, Delta, and Omicron variants in the US.  \n",
    "2. Store the result as a dictionary where keys are variant names and values are percentages.  \n",
    "3. Save in variable = proc_seq_us\n",
    "\n",
    "`=> Other implied items based on same exercise for manager last year`\n",
    "- Determine each country's total processed sequences for Omicron on December 27, 2021 or any other date entered (date updated from 2020).\n",
    "- provide country name and # processed sequences\n",
    "- bidirectional sorting\n",
    "- store outcomes in tuple like mytuple(country_name, processed_sequen, ) \n",
    "- variables totals like `total_omicron_2021`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e835919",
   "metadata": {
    "id": "sMFoLYaXlRGZ"
   },
   "source": [
    "**`=> Instructions for jr. developer`**\n",
    "\n",
    "\n",
    "`Before moving forward and fixing the code, please have a quick overview of the following notebook so you can familiarize with some of the things you can do with pandas given the related COVID data:` [Pandas Basics and COVID Data](https://www.kaggle.com/code/albertomacasalcibar/pandas-basics/notebook)\n",
    "\n",
    "\n",
    "In general, you will need to import the following module\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "\n",
    "Once you add the pandas module, you may notice that the data source is also missing. So, in this particular case, one simple way to get a dataframe populated for each context is to use the following code snippet:\n",
    "\n",
    "`import pandas as pd`\n",
    "<br>\n",
    "`file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"`\n",
    "<br>\n",
    "`df = pd.read_csv(file_url)`\n",
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Notice:</b> I already made some changes to the code which is inline with my recommendations\n",
    "this way you can see the code working as expected and be ready for some extra improvements if needed.\n",
    "</div>\n",
    "\n",
    "Now, lets consider a few more specific cases and some fixes:\n",
    "\n",
    "`=>CASE 5a - `\n",
    "\n",
    "1. Consider replacing all cases of the variable name `df6` with `df`. There seems to be no need to have 2 different dataframes.\n",
    "\n",
    "2. Reading the code structure, it seems that the proper code for #5.4 is:\n",
    "\n",
    "    `total_omicron_2021 = list(zip(df.index, df))`\n",
    "\n",
    "3. Replace variable `missing` with `total_omicron_2021` so that it looks like this:\n",
    "   \n",
    "    #5.5\n",
    "    `df7 = pd.DataFrame(sorted(total_omicron_2021, key=lambda x: x[1], reverse=True))`\n",
    "\n",
    "`=> CASE 5b and 5c are similar to case 5a. `\n",
    "***\n",
    "\n",
    "`=> Code readability & Maintenance`**`(optional)`**\n",
    "*The following are just suggestions as the code should be working already.*\n",
    "\n",
    "Please consider the use `pandas.query()` functionality to simplify and make filters more readable\n",
    "\n",
    "For instance, in case 5b, you can consider replacing the following code:\n",
    "\n",
    "`df2 = df2.loc[(\"United States\", [\"Alpha\", \"Delta\", \"Omicron\"]), :].loc[\"United States\"]`\n",
    "\n",
    "with a more readable and maintainable code:\n",
    "\n",
    "`df2.query(\"location in ('United States') and variant in ('Alpha','Delta','Omicron')\", inplace=True)`\n",
    "\n",
    "Consider changing the `loc()` statement to use `query()` for maintenance improve purpose\n",
    "\n",
    "`df2.query(\"location in ('United States') and variant in ('Alpha','Delta','Omicron')\", inplace=True)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uV6K5AkAfDET",
   "metadata": {
    "id": "uV6K5AkAfDET"
   },
   "source": [
    "#### `5a - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "qUkhMZD8T40i",
   "metadata": {
    "id": "qUkhMZD8T40i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0      1\n",
      "0   United Kingdom  52456\n",
      "1    United States  24681\n",
      "2          Denmark   3331\n",
      "3          Germany   1701\n",
      "4           Israel   1578\n",
      "..             ...    ...\n",
      "59         Vietnam      1\n",
      "60         Moldova      0\n",
      "61          Monaco      0\n",
      "62           Nepal      0\n",
      "63     South Korea      0\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#=> I of III - broken code last year\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "\n",
    "# format float number to display only 1 decimal place\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "total_omicron_2021 = []\n",
    "#5.1\n",
    "df = df.set_index(\"location\")\n",
    "#5.2\n",
    "df = df.loc[df[\"date\"] == \"2021-12-27\"]\n",
    "#5.3\n",
    "df = df.loc[df[\"variant\"] == \"Omicron\"]\n",
    "\n",
    "#5.3\n",
    "df = df[\"num_sequences\"]\n",
    "\n",
    "#5.4\n",
    "total_omicron_2021 = list(zip(df.index, df))\n",
    "\n",
    "#5.5\n",
    "df7 = pd.DataFrame(sorted(total_omicron_2021, key=lambda x: x[1], reverse=True))\n",
    "print(df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dzXyv7kGZlBP",
   "metadata": {
    "id": "dzXyv7kGZlBP"
   },
   "source": [
    "##### **`5a - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g1qcVGxqavtv",
   "metadata": {
    "id": "g1qcVGxqavtv"
   },
   "source": [
    "```\n",
    "0\t                1\n",
    "0\tUnited Kingdom\t52456\n",
    "1\tUnited States\t  24681\n",
    "2\tDenmark\t        3331\n",
    "3\tGermany\t        1701\n",
    "4\tIsrael\t        1578\n",
    "...\t...\t...\n",
    "59\tVietnam\t      1\n",
    "60\tMoldova\t      0\n",
    "61\tMonaco\t      0\n",
    "62\tNepal\t        0\n",
    "63\tSouth Korea \t0\n",
    "64 rows × 2 columns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5G3szw10bNTr",
   "metadata": {
    "id": "5G3szw10bNTr"
   },
   "source": [
    "#### `5b - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6cf6efa9",
   "metadata": {
    "id": "6cf6efa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('United States', 'Alpha'): 11.520951617373877, ('United States', 'Delta'): 63.76796208057254, ('United States', 'Omicron'): 1.370817855027461}\n"
     ]
    }
   ],
   "source": [
    "#=> II of III - broken code last year\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "\n",
    "proc_seq_us = {}\n",
    "df2 = df.groupby([\"location\", \"variant\"]).aggregate({\n",
    "    \"num_sequences\": \"sum\",\n",
    "    \"num_sequences_total\": \"sum\",\n",
    "})\n",
    "df2[\"perc_sequences\"] = (df2[\"num_sequences\"] / df2[\"num_sequences_total\"]) * 100\n",
    "#df2 = df2.loc[(\"United States\", [\"Alpha\", \"Delta\", \"Omicron\"]), :].loc[\"United States\"]\n",
    "df2.query(\"location in ('United States') and variant in ('Alpha','Delta','Omicron')\", inplace=True)\n",
    "\n",
    "df2 = df2[\"perc_sequences\"]\n",
    "proc_seq_us = df2.to_dict()\n",
    "print(proc_seq_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NfYB_LjbZ_zq",
   "metadata": {
    "id": "NfYB_LjbZ_zq"
   },
   "source": [
    "##### **`5b - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_TI3iusnbUbO",
   "metadata": {
    "id": "_TI3iusnbUbO"
   },
   "source": [
    "```\n",
    "{'Alpha': 11.520951617373877, 'Delta': 63.76796208057254, \n",
    "                                                'Omicron': 1.370817855027461}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ySKYi-77bbXc",
   "metadata": {
    "id": "ySKYi-77bbXc"
   },
   "source": [
    "#### `5c - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ilcLFMXTW9jG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilcLFMXTW9jG",
    "outputId": "2b827e05-e959-4580-861d-518facb7c1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0      1\n",
      "0   United Kingdom  52456\n",
      "1    United States  24681\n",
      "2          Denmark   3331\n",
      "3          Germany   1701\n",
      "4           Israel   1578\n",
      "..             ...    ...\n",
      "59         Vietnam      1\n",
      "60         Moldova      0\n",
      "61          Monaco      0\n",
      "62           Nepal      0\n",
      "63     South Korea      0\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "[('United Kingdom', 52456), ('United States', 24681), ('Denmark', 3331), ('Germany', 1701), ('Israel', 1578), ('Australia', 1319), ('Switzerland', 514), ('France', 509), ('Italy', 486), ('Belgium', 464), ('Spain', 461), ('Sweden', 434), ('Chile', 260), ('Netherlands', 254), ('Singapore', 249), ('Mexico', 240), ('Turkey', 202), ('India', 174), ('Brazil', 147), ('Botswana', 142), ('Indonesia', 128), ('Japan', 118), ('Portugal', 118), ('Argentina', 80), ('New Zealand', 63), ('South Africa', 61), ('Lithuania', 50), ('Czechia', 49), ('Georgia', 46), ('Russia', 45), ('Colombia', 37), ('Sri Lanka', 37), ('Hong Kong', 35), ('Malta', 34), ('Poland', 28), ('Ecuador', 26), ('Canada', 25), ('Jordan', 22), ('Malawi', 21), ('Cambodia', 18), ('Norway', 17), ('Morocco', 15), ('Senegal', 15), ('Costa Rica', 14), ('Pakistan', 11), ('Nigeria', 10), ('Peru', 10), ('Brunei', 8), ('Slovakia', 8), ('Trinidad and Tobago', 8), ('Maldives', 7), ('Zambia', 7), ('Thailand', 6), ('Malaysia', 5), ('Bangladesh', 4), ('Romania', 3), ('Iran', 1), ('Oman', 1), ('Ukraine', 1), ('Vietnam', 1), ('Moldova', 0), ('Monaco', 0), ('Nepal', 0), ('South Korea', 0)]\n"
     ]
    }
   ],
   "source": [
    "#=> III of III - broken code last year\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "total_omicron_2021 = []\n",
    "#5.1\n",
    "df6 = df6.set_index(\"location\")\n",
    "#5.2\n",
    "df6 = df6.loc[df6[\"date\"] == \"2021-12-27\"]\n",
    "#5.3#\n",
    "df6 = df6.loc[df6[\"variant\"] == \"Omicron\"]\n",
    "#5.3\n",
    "df6 = df6[\"num_sequences\"]\n",
    "#5.4\n",
    "total_omicron_2021 = list(zip(df6.index, df6))\n",
    "#5.5\n",
    "df7 = pd.DataFrame(sorted(total_omicron_2021, key=lambda x: x[1], reverse=True))\n",
    "print(df7)\n",
    "total_omicron_2021 = sorted(total_omicron_2021, key=lambda x: x[1], reverse=True)\n",
    "print(total_omicron_2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3c3REubaSEx",
   "metadata": {
    "id": "x3c3REubaSEx"
   },
   "source": [
    "##### **`5c - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2JNdnFwTap_f",
   "metadata": {
    "id": "2JNdnFwTap_f"
   },
   "source": [
    "```\n",
    "                 0      1\n",
    "0   United Kingdom  52456\n",
    "1    United States  24681\n",
    "2          Denmark   3331\n",
    "3          Germany   1701\n",
    "4           Israel   1578\n",
    "..             ...    ...\n",
    "59         Vietnam      1\n",
    "60         Moldova      0\n",
    "61          Monaco      0\n",
    "62           Nepal      0\n",
    "63     South Korea      0\n",
    "[64 rows x 2 columns]\n",
    "\n",
    "#[('United Kingdom', 52456), ('United States', 24681), ('Denmark', 3331),\n",
    " ('Germany', 1701), ('Israel', 1578), ('Australia', 1319), ('Switzerland', 514),\n",
    "  ('France', 509), ('Italy', 486), ('Belgium', 464), ('Spain', 461), \n",
    "  ('Sweden', 434), ('Chile', 260), ('Netherlands', 254), ('Singapore', 249),\n",
    "  ('Mexico', 240), ('Turkey', 202), ('India', 174), ('Brazil', 147),\n",
    "   ('Botswana', 142), ('Indonesia', 128), ('Japan', 118), ('Portugal', 118),\n",
    "    ('Argentina', 80), ('New Zealand', 63), ('South Africa', 61), \n",
    "    ('Lithuania', 50), ('Czechia', 49), ('Georgia', 46), ('Russia', 45), \n",
    "    ('Colombia', 37), ('Sri Lanka', 37), ('Hong Kong', 35), ('Malta', 34),\n",
    "     ('Poland', 28), ('Ecuador', 26), ('Canada', 25), ('Jordan', 22), \n",
    "     ('Malawi', 21), ('Cambodia', 18), ('Norway', 17), ('Morocco', 15), \n",
    "     ('Senegal', 15), ('Costa Rica', 14), ('Pakistan', 11), ('Nigeria', 10),\n",
    "      ('Peru', 10), ('Brunei', 8), ('Slovakia', 8), ('Trinidad and Tobago', 8),\n",
    "       ('Maldives', 7), ('Zambia', 7), ('Thailand', 6), ('Malaysia', 5), \n",
    "       ('Bangladesh', 4), ('Romania', 3), ('Iran', 1), ('Oman', 1),\n",
    "        ('Ukraine', 1), ('Vietnam', 1), ('Moldova', 0), ('Monaco', 0), \n",
    "        ('Nepal', 0), ('South Korea', 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kjA00fVqPjEm",
   "metadata": {
    "id": "kjA00fVqPjEm"
   },
   "source": [
    "## `M.1. Wrap.up and Housekeeping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2DzgneXkPhuC",
   "metadata": {
    "id": "2DzgneXkPhuC"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.flush_and_unmount()\n",
    "\n",
    "##=>Perform A,B,C when done with spark\n",
    "#A: \n",
    "#=> Close the SparkSession\n",
    "spark.stop()\n",
    "\n",
    "#B:\n",
    "#=> Disconnect and stop Spark in a Jupyter Notebook,\n",
    "#=> stops SparkContext and releases its resourcs\n",
    "sc.stop()\n",
    "\n",
    "#C: \n",
    "#=> Confirm Spark termination by checking the Spark UI\n",
    "#=> Access UI by visiting URL provided in Notebook output where Spark fireup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QuEPQ9tfwvRH",
   "metadata": {
    "id": "QuEPQ9tfwvRH"
   },
   "source": [
    "# `<end.M1` ~ `M1.end>`\n",
    "-------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "el9sjRdm9gjv",
    "7o91Ig5QKVif",
    "MqZm_iFTPI7f",
    "JfIew_dgmpCQ",
    "kRoOscDyqoCO",
    "wcrKuRsWXUW1",
    "913dpFR0Fp1E",
    "kjA00fVqPjEm"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
